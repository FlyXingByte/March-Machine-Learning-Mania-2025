Running March Mania prediction pipeline from 2021 onwards for Stage 2
Loading data files from 2021 and onwards
Regular season data: Reduced from 199757 rows to 50065 rows
Tournament data: Reduced from 2276 rows to 531 rows
Seed data: Reduced from 4234 rows to 540 rows
Loaded 758 teams from MTeams and WTeams.
Successfully loaded submission file: Z:\kaggle\MMLM2025\March-Machine-Learning-Mania-2025\input\march-machine-learning-mania-2025\SampleSubmissionStage2.csv
Merged KenPom data loading has been disabled.
Original KenPom data loading has been disabled.
Merged game data total rows: 50596
Performing feature engineering...
Performing basic feature engineering...
Calculating team statistics features (regular season data only, to avoid data leakage)...
Team statistics features calculation complete, processed 3576 team-season combinations
Calculating head-to-head features...
Head-to-head features calculation complete
Adding recent performance features (window = 5)...
  Recent performance features added
Adding advanced predictive features...
Calculating Elo rating features...
Elo rating features calculation complete, processed 1788 teams
Calculating strength of schedule (SOS) features...
赛程强度特征计算完成，共处理了 3576 个团队-赛季组合
Calculating key statistical differential features...
关键统计差异特征计算完成
增强关键统计差异特征，添加篮板率、失误率、有效命中率等冠军指标...
  计算详细的高级统计指标差异...
关键冠军指标增强完成，添加了以下新指标:
  - 有效投篮命中率差异 (EFGPctDiff)
  - 真实命中率差异 (TSPctDiff)
  - 罚球率及命中率差异 (FTRateDiff, FTPctDiff)
  - 进攻篮板率、防守篮板率及总篮板率差异
  - 冠军综合指标 (ChampionComposite, ChampionCompositeV2)
  所有关键指标可用，创建综合'四因素'指标...
Calculating historical tournament performance features...
历史锦标赛表现特征计算完成
Merged KenPom features have been disabled.
聚合团队对阵统计特征（仅使用常规赛数据，避免数据泄露）...
使用 50065 场常规赛比赛进行特征聚合（总共 50596 场比赛）
z:\kaggle\MMLM2025\March-Machine-Learning-Mania-2025\src\feature_engineering.py:753: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.
  gb = gb.drop(columns=['SeasonIDTeams'])
聚合特征计算完成，共生成 35188 个赛季-团队对组合的特征
Current season: 2025
Training data rows after filtering: 50596
为提交文件准备特征数据...
提交文件特征准备完成
Adding advanced predictive features to submission data...
Calculating Elo rating features...
  Info: Using row index for game ordering in submission data (no DayNum column needed).
Elo rating features calculation complete, processed 363 teams
Calculating strength of schedule (SOS) features...
赛程强度特征计算完成，共处理了 726 个团队-赛季组合
Calculating key statistical differential features...
  No detailed game statistics found. This is likely submission data.
  Setting default statistical values for differentials.
增强关键统计差异特征，添加篮板率、失误率、有效命中率等冠军指标...
  部分统计数据未找到，设置默认值...
  设置了默认值的关键指标: []
Calculating historical tournament performance features...
历史锦标赛表现特征计算完成
Merged KenPom features for submission have been disabled.
Common columns count: 104
Sample common columns: ['SeedTrendDiff', 'SeedDiff', 'SOS_OffRatingDiff', 'Team2SeedStrength', 'Team2_SeedTrend']
GenderCode column found in training data
GenderCode column found in submission data
Using 98 features for training, sample features: ['Season', 'GameType', 'GenderCode', 'Team1Seed', 'Team2Seed']
Found tracking columns: ['original_index', 'original_ID']
Training features shape: (50596, 98)
Submission features shape: (131407, 100)
Training data shape: (50596, 98)
Prediction data shape: (131407, 100)
Submission data shape before modeling: (131407, 118)
Finding best threshold based on Brier Score using time-series cross-validation...
Found 5 seasons for time series validation: [2021 2022 2023 2024 2025]
  Validating season 2022, training on seasons [2021]
Aligning features between training and test data...
  After alignment: 99 valid features for modeling
  Train shape: (7540, 99), Test shape: (10539, 99)
Warning: No valid folds were processed in time-series CV. Using default prediction 0.5.     
  Season 2022 validation complete, validation set size: 10539
  Validating season 2023, training on seasons [2021 2022]
Aligning features between training and test data...
  After alignment: 99 valid features for modeling
  Train shape: (18079, 99), Test shape: (11110, 99)
Epoch [5/20], Train Loss: 0.0520, Val Loss: 0.0545
Epoch [10/20], Train Loss: 0.0314, Val Loss: 0.0393
Epoch [15/20], Train Loss: 0.0197, Val Loss: 0.0385
Epoch [20/20], Train Loss: 0.0141, Val Loss: 0.0371
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch [5/25], Train Loss: 0.0789, Val Loss: 0.0496
Epoch [10/25], Train Loss: 0.0567, Val Loss: 0.0348
Epoch [15/25], Train Loss: 0.0452, Val Loss: 0.0332
Epoch [20/25], Train Loss: 0.0312, Val Loss: 0.0287
Epoch [25/25], Train Loss: 0.0326, Val Loss: 0.0294

[Stacking] Average temporary fold Brier Score: 0.0093
z:\kaggle\MMLM2025\March-Machine-Learning-Mania-2025\src\models.py:668: RuntimeWarning: invalid value encountered in log
  logits = np.log(preds / (1 - preds + 1e-8))
  Season 2023 validation complete, validation set size: 11110
  Validating season 2024, training on seasons [2021 2022 2023]
Aligning features between training and test data...
  After alignment: 99 valid features for modeling
  Train shape: (29189, 99), Test shape: (11155, 99)
Epoch [5/20], Train Loss: 0.0520, Val Loss: 0.0545
Epoch [10/20], Train Loss: 0.0314, Val Loss: 0.0393
Epoch [15/20], Train Loss: 0.0197, Val Loss: 0.0385
Epoch [20/20], Train Loss: 0.0141, Val Loss: 0.0371
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch [5/25], Train Loss: 0.0789, Val Loss: 0.0496
Epoch [10/25], Train Loss: 0.0567, Val Loss: 0.0348
Epoch [15/25], Train Loss: 0.0452, Val Loss: 0.0332
Epoch [20/25], Train Loss: 0.0312, Val Loss: 0.0287
Epoch [25/25], Train Loss: 0.0326, Val Loss: 0.0294
Epoch [5/20], Train Loss: 0.0428, Val Loss: 0.0383
Epoch [10/20], Train Loss: 0.0258, Val Loss: 0.0351
Epoch [15/20], Train Loss: 0.0196, Val Loss: 0.0342
Early stopping at epoch 17
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch [5/25], Train Loss: 0.0676, Val Loss: 0.0387
Epoch [10/25], Train Loss: 0.0497, Val Loss: 0.0334
Epoch [15/25], Train Loss: 0.0331, Val Loss: 0.0263
Epoch [20/25], Train Loss: 0.0294, Val Loss: 0.0286
Early stopping at epoch 22

[Stacking] Average temporary fold Brier Score: 0.0100
z:\kaggle\MMLM2025\March-Machine-Learning-Mania-2025\src\models.py:668: RuntimeWarning: invalid value encountered in log
  logits = np.log(preds / (1 - preds + 1e-8))
  Season 2024 validation complete, validation set size: 11155
  Validating season 2025, training on seasons [2021 2022 2023 2024]
Aligning features between training and test data...
  After alignment: 99 valid features for modeling
  Train shape: (40344, 99), Test shape: (10252, 99)
Epoch [5/20], Train Loss: 0.0520, Val Loss: 0.0545
Epoch [10/20], Train Loss: 0.0314, Val Loss: 0.0393
Epoch [15/20], Train Loss: 0.0197, Val Loss: 0.0385
Epoch [20/20], Train Loss: 0.0141, Val Loss: 0.0371
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch [5/25], Train Loss: 0.0789, Val Loss: 0.0496
Epoch [10/25], Train Loss: 0.0567, Val Loss: 0.0348
Epoch [15/25], Train Loss: 0.0452, Val Loss: 0.0332
Epoch [20/25], Train Loss: 0.0312, Val Loss: 0.0287
Epoch [25/25], Train Loss: 0.0326, Val Loss: 0.0294
Epoch [5/20], Train Loss: 0.0428, Val Loss: 0.0383
Epoch [10/20], Train Loss: 0.0258, Val Loss: 0.0351
Epoch [15/20], Train Loss: 0.0196, Val Loss: 0.0342
Early stopping at epoch 17
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch [5/25], Train Loss: 0.0676, Val Loss: 0.0387
Epoch [10/25], Train Loss: 0.0497, Val Loss: 0.0334
Epoch [15/25], Train Loss: 0.0331, Val Loss: 0.0263
Epoch [20/25], Train Loss: 0.0294, Val Loss: 0.0286
Early stopping at epoch 22
Epoch [5/20], Train Loss: 0.0396, Val Loss: 0.0411
Epoch [10/20], Train Loss: 0.0280, Val Loss: 0.0359
Early stopping at epoch 14
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch [5/25], Train Loss: 0.0603, Val Loss: 0.0365
Epoch [10/25], Train Loss: 0.0457, Val Loss: 0.0307
Epoch [15/25], Train Loss: 0.0424, Val Loss: 0.0303
Epoch [20/25], Train Loss: 0.0381, Val Loss: 0.0331
Epoch [25/25], Train Loss: 0.0310, Val Loss: 0.0300

[Stacking] Average temporary fold Brier Score: 0.0097
z:\kaggle\MMLM2025\March-Machine-Learning-Mania-2025\src\models.py:668: RuntimeWarning: invalid value encountered in log
  logits = np.log(preds / (1 - preds + 1e-8))
  Season 2025 validation complete, validation set size: 10252
Time series validation complete, using 43056 samples for threshold optimization
Best threshold: 0.01, Brier Score: 0.4970
Best threshold based on Brier Score: 0.0100
Starting training and prediction...

Stacking ensemble with time-series cross-validation
Input data shapes: X_train=(50596, 98), y_train=(50596,), X_test=(131407, 100)
Using 99 features
Available seasons: [2021, 2022, 2023, 2024, 2025]
Performing time series cross-validation:
  Split 1: Train on [2021], validate on 2022
  Split 2: Train on [2021, 2022], validate on 2023
  Split 3: Train on [2021, 2022, 2023], validate on 2024
  Split 4: Train on [2021, 2022, 2023, 2024], validate on 2025
Aligning features between training and test data...
  After alignment: 99 valid features for modeling
  Train shape: (50596, 99), Test shape: (131407, 99)

Processing fold 1/4
One-hot encoding 'GameType' feature for training, validation and test sets.
  Training base model 1/18: XGBClassifier
    XGBClassifier Brier score: 0.0130
  Training base model 2/18: LogisticRegression
    LogisticRegression Brier score: 0.0303
  Training base model 3/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0366
  Training base model 4/18: ExtraTreesClassifier
    ExtraTreesClassifier Brier score: 0.0480
  Training base model 5/18: RandomForestClassifier
    RandomForestClassifier Brier score: 0.0398
  Training base model 6/18: CatBoostClassifier
    CatBoostClassifier Brier score: 0.0168
  Training base model 7/18: LGBMClassifier
    LGBMClassifier Brier score: 0.0116
  Training base model 8/18: PyTorchMLPWrapper
Epoch [5/20], Train Loss: 0.0520, Val Loss: 0.0545
Epoch [10/20], Train Loss: 0.0314, Val Loss: 0.0393
Epoch [15/20], Train Loss: 0.0197, Val Loss: 0.0385
Epoch [20/20], Train Loss: 0.0141, Val Loss: 0.0371
    PyTorchMLPWrapper Brier score: 0.0287
  Training base model 9/18: GradientBoostingClassifier
    GradientBoostingClassifier Brier score: 0.0141
  Training base model 10/18: HistGradientBoostingClassifier
    HistGradientBoostingClassifier Brier score: 0.0131
  Training base model 11/18: AdaBoostClassifier
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
    AdaBoostClassifier Brier score: 0.1852
  Training base model 12/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0600
  Training base model 13/18: KNeighborsClassifier
    KNeighborsClassifier Brier score: 0.0531
  Training base model 14/18: GaussianNB
    GaussianNB Brier score: 0.1276
  Training base model 15/18: MLPClassifier
    MLPClassifier Brier score: 0.0163
  Training base model 16/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0328
  Training base model 17/18: DecisionTreeClassifier
    DecisionTreeClassifier Brier score: 0.0497
  Training base model 18/18: PyTorchDeepNNWrapper
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch [5/25], Train Loss: 0.0789, Val Loss: 0.0496
Epoch [10/25], Train Loss: 0.0567, Val Loss: 0.0348
Epoch [15/25], Train Loss: 0.0452, Val Loss: 0.0332
Epoch [20/25], Train Loss: 0.0312, Val Loss: 0.0287
Epoch [25/25], Train Loss: 0.0326, Val Loss: 0.0294
    PyTorchDeepNNWrapper Brier score: 0.0123
  Current fold temporary meta-model Brier score: 0.0093

Processing fold 2/4
One-hot encoding 'GameType' feature for training, validation and test sets.
  Training base model 1/18: XGBClassifier
    XGBClassifier Brier score: 0.0155
  Training base model 2/18: LogisticRegression
    LogisticRegression Brier score: 0.0320
  Training base model 3/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0412
  Training base model 4/18: ExtraTreesClassifier
    ExtraTreesClassifier Brier score: 0.0489
  Training base model 5/18: RandomForestClassifier
    RandomForestClassifier Brier score: 0.0381
  Training base model 6/18: CatBoostClassifier
    CatBoostClassifier Brier score: 0.0143
  Training base model 7/18: LGBMClassifier
    LGBMClassifier Brier score: 0.0146
  Training base model 8/18: PyTorchMLPWrapper
Epoch [5/20], Train Loss: 0.0428, Val Loss: 0.0383
Epoch [10/20], Train Loss: 0.0258, Val Loss: 0.0351
Epoch [15/20], Train Loss: 0.0196, Val Loss: 0.0342
Early stopping at epoch 17
    PyTorchMLPWrapper Brier score: 0.0124
  Training base model 9/18: GradientBoostingClassifier
    GradientBoostingClassifier Brier score: 0.0166
  Training base model 10/18: HistGradientBoostingClassifier
    HistGradientBoostingClassifier Brier score: 0.0168
  Training base model 11/18: AdaBoostClassifier
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
    AdaBoostClassifier Brier score: 0.1852
  Training base model 12/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0227
  Training base model 13/18: KNeighborsClassifier
    KNeighborsClassifier Brier score: 0.0574
  Training base model 14/18: GaussianNB
    GaussianNB Brier score: 0.1402
  Training base model 15/18: MLPClassifier
    MLPClassifier Brier score: 0.0152
  Training base model 16/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0343
  Training base model 17/18: DecisionTreeClassifier
    DecisionTreeClassifier Brier score: 0.0523
  Training base model 18/18: PyTorchDeepNNWrapper
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch [5/25], Train Loss: 0.0676, Val Loss: 0.0387
Epoch [10/25], Train Loss: 0.0497, Val Loss: 0.0334
Epoch [15/25], Train Loss: 0.0331, Val Loss: 0.0263
Epoch [20/25], Train Loss: 0.0294, Val Loss: 0.0286
Early stopping at epoch 22
    PyTorchDeepNNWrapper Brier score: 0.0110
  Current fold temporary meta-model Brier score: 0.0108

Processing fold 3/4
One-hot encoding 'GameType' feature for training, validation and test sets.
  Training base model 1/18: XGBClassifier
    XGBClassifier Brier score: 0.0127
  Training base model 2/18: LogisticRegression
    LogisticRegression Brier score: 0.0283
  Training base model 3/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0382
  Training base model 4/18: ExtraTreesClassifier
    ExtraTreesClassifier Brier score: 0.0465
  Training base model 5/18: RandomForestClassifier
    RandomForestClassifier Brier score: 0.0358
  Training base model 6/18: CatBoostClassifier
    CatBoostClassifier Brier score: 0.0114
  Training base model 7/18: LGBMClassifier
    LGBMClassifier Brier score: 0.0125
  Training base model 8/18: PyTorchMLPWrapper
Epoch [5/20], Train Loss: 0.0396, Val Loss: 0.0411
Epoch [10/20], Train Loss: 0.0280, Val Loss: 0.0359
Early stopping at epoch 14
    PyTorchMLPWrapper Brier score: 0.0109
  Training base model 9/18: GradientBoostingClassifier
    GradientBoostingClassifier Brier score: 0.0154
  Training base model 10/18: HistGradientBoostingClassifier
    HistGradientBoostingClassifier Brier score: 0.0160
  Training base model 11/18: AdaBoostClassifier
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
    AdaBoostClassifier Brier score: 0.1854
  Training base model 12/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0185
  Training base model 13/18: KNeighborsClassifier
    KNeighborsClassifier Brier score: 0.0555
  Training base model 14/18: GaussianNB
    GaussianNB Brier score: 0.1410
  Training base model 15/18: MLPClassifier
    MLPClassifier Brier score: 0.0126
  Training base model 16/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0302
  Training base model 17/18: DecisionTreeClassifier
    DecisionTreeClassifier Brier score: 0.0506
  Training base model 18/18: PyTorchDeepNNWrapper
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch [5/25], Train Loss: 0.0603, Val Loss: 0.0365
Epoch [10/25], Train Loss: 0.0457, Val Loss: 0.0307
Epoch [15/25], Train Loss: 0.0424, Val Loss: 0.0303
Epoch [20/25], Train Loss: 0.0381, Val Loss: 0.0331
Epoch [25/25], Train Loss: 0.0310, Val Loss: 0.0300
    PyTorchDeepNNWrapper Brier score: 0.0098
  Current fold temporary meta-model Brier score: 0.0089

Processing fold 4/4
One-hot encoding 'GameType' feature for training, validation and test sets.
  Training base model 1/18: XGBClassifier
    XGBClassifier Brier score: 0.0143
  Training base model 2/18: LogisticRegression
    LogisticRegression Brier score: 0.0309
  Training base model 3/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0410
  Training base model 4/18: ExtraTreesClassifier
    ExtraTreesClassifier Brier score: 0.0459
  Training base model 5/18: RandomForestClassifier
    RandomForestClassifier Brier score: 0.0349
  Training base model 6/18: CatBoostClassifier
    CatBoostClassifier Brier score: 0.0131
  Training base model 7/18: LGBMClassifier
    LGBMClassifier Brier score: 0.0131
  Training base model 8/18: PyTorchMLPWrapper
Epoch [5/20], Train Loss: 0.0365, Val Loss: 0.0349
Epoch [10/20], Train Loss: 0.0273, Val Loss: 0.0354
Early stopping at epoch 13
    PyTorchMLPWrapper Brier score: 0.0123
  Training base model 9/18: GradientBoostingClassifier
    GradientBoostingClassifier Brier score: 0.0170
  Training base model 10/18: HistGradientBoostingClassifier
    HistGradientBoostingClassifier Brier score: 0.0173
  Training base model 11/18: AdaBoostClassifier
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\sklearn\ensemble\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(
    AdaBoostClassifier Brier score: 0.1845
  Training base model 12/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0210
  Training base model 13/18: KNeighborsClassifier
    KNeighborsClassifier Brier score: 0.0551
  Training base model 14/18: GaussianNB
    GaussianNB Brier score: 0.1263
  Training base model 15/18: MLPClassifier
    MLPClassifier Brier score: 0.0128
  Training base model 16/18: CalibratedClassifierCV
    CalibratedClassifierCV Brier score: 0.0318
  Training base model 17/18: DecisionTreeClassifier
    DecisionTreeClassifier Brier score: 0.0523
  Training base model 18/18: PyTorchDeepNNWrapper
C:\Users\Mengfei\anaconda3\envs\autogluon\lib\site-packages\torch\optim\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch [5/25], Train Loss: 0.0562, Val Loss: 0.0339
Epoch [10/25], Train Loss: 0.0478, Val Loss: 0.0312
Epoch [15/25], Train Loss: 0.0375, Val Loss: 0.0275
Epoch [20/25], Train Loss: 0.0322, Val Loss: 0.0266
Epoch [25/25], Train Loss: 0.0292, Val Loss: 0.0289
    PyTorchDeepNNWrapper Brier score: 0.0135
  Current fold temporary meta-model Brier score: 0.0108

Average model performance across folds:
  PyTorchDeepNNWrapper: 0.0116
  LGBMClassifier: 0.0130
  XGBClassifier: 0.0138
  CatBoostClassifier: 0.0139
  MLPClassifier: 0.0142
  GradientBoostingClassifier: 0.0157
  HistGradientBoostingClassifier: 0.0158
  PyTorchMLPWrapper: 0.0161
  LogisticRegression: 0.0304
  CalibratedClassifierCV: 0.0340
  RandomForestClassifier: 0.0372
  ExtraTreesClassifier: 0.0473
  DecisionTreeClassifier: 0.0512
  KNeighborsClassifier: 0.0553
  GaussianNB: 0.1338
  AdaBoostClassifier: 0.1851

Model weights for ensemble:
  PyTorchDeepNNWrapper: 0.1182
  LGBMClassifier: 0.1060
  XGBClassifier: 0.0993
  CatBoostClassifier: 0.0989
  MLPClassifier: 0.0966
  GradientBoostingClassifier: 0.0873
  HistGradientBoostingClassifier: 0.0870
  PyTorchMLPWrapper: 0.0856
  LogisticRegression: 0.0452
  CalibratedClassifierCV: 0.0404
  RandomForestClassifier: 0.0370
  ExtraTreesClassifier: 0.0291
  DecisionTreeClassifier: 0.0268
  KNeighborsClassifier: 0.0249
  GaussianNB: 0.0103
  AdaBoostClassifier: 0.0074
Training final meta-model (Logistic Regression) on out-of-fold predictions
Out-of-fold meta-model Brier score: 0.0102
Final meta-model coefficients:
    XGBClassifier: -0.3694
    LogisticRegression: 1.5673
    CalibratedClassifierCV: 0.1681
    ExtraTreesClassifier: 2.4305
    RandomForestClassifier: 0.2686
    CatBoostClassifier: 2.9358
    LGBMClassifier: 0.0108
    PyTorchMLPWrapper: 1.0688
    GradientBoostingClassifier: 0.1047
    HistGradientBoostingClassifier: 0.6999
    AdaBoostClassifier: -2.2707
    CalibratedClassifierCV: -1.4804
    KNeighborsClassifier: 1.5546
    GaussianNB: -0.5312
    MLPClassifier: 0.5196
    CalibratedClassifierCV: 1.0892
    DecisionTreeClassifier: 0.2693
    PyTorchDeepNNWrapper: 2.9956

[Stacking] Average temporary fold Brier Score: 0.0100
Generating initial submission file...
Test predictions shape: (131407,)
Used direct alignment with tracking columns to create submission with 131407 rows
Sample submission:
               ID      Pred
0  2025_1101_1102  0.911160
1  2025_1101_1103  0.075260
2  2025_1101_1104  0.092423
3  2025_1101_1105  0.807608
4  2025_1101_1106  0.582429
Total predictions: 131407

Prediction value distribution:
  Min: 0.0172
  Max: 0.9858
  Mean: 0.5231
  Std: 0.3091
  25% quantile: 0.2156
  50% quantile: 0.5340
  75% quantile: 0.8373

Prediction value histogram:
  0.0-0.1: 11389 (8.67%)
  0.1-0.2: 19160 (14.58%)
  0.2-0.3: 13131 (9.99%)
  0.3-0.4: 10326 (7.86%)
  0.4-0.5: 8884 (6.76%)
  0.5-0.6: 8298 (6.31%)
  0.6-0.7: 9476 (7.21%)
  0.7-0.8: 12065 (9.18%)
  0.8-0.9: 20087 (15.29%)
  0.9-1.0: 18591 (14.15%)

Final submission has 131407 rows
✓ Matches sample submission format (131,407 rows)
Pipeline complete! Submission saved to submission.csv